{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luLVS-FiONEp",
        "outputId": "5b74f16d-f391-4819-fdd7-7b6bdca1974f"
      },
      "outputs": [],
      "source": [
        "#@title Download the German Traffic Signs Dataset\n",
        "!wget https://d17h27t6h515a5.cloudfront.net/topher/2017/February/5898cd6f_traffic-signs-data/traffic-signs-data.zip\n",
        "!wget https://raw.githubusercontent.com/AvivSham/German-Traffic-Signs-Classification/master/signnames.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kODZm-nFOQZV",
        "outputId": "0aeeb588-11ec-4c6f-bcdd-e49f52efc0f9"
      },
      "outputs": [],
      "source": [
        "!unzip traffic-signs-data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtgzFwQjOnXd"
      },
      "outputs": [],
      "source": [
        "#@title Import dependencies\n",
        "%matplotlib inline\n",
        "import os, pickle, shutil\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import skimage.morphology as morp\n",
        "from skimage.filters import rank\n",
        "from sklearn.utils import shuffle, compute_class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import csv\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Input, Model\n",
        "\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras import optimizers\n",
        "from keras.initializers import random_normal\n",
        "from keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint\n",
        "import seaborn as sn\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGxk2yA0jBOx"
      },
      "outputs": [],
      "source": [
        "# constrain seed\n",
        "np.random.seed(seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOYzpzKrYQsM"
      },
      "outputs": [],
      "source": [
        "#@title Moving the data files to directory\n",
        "!mkdir data\n",
        "for i in os.listdir():\n",
        "  if '.p' in i:\n",
        "    shutil.move('./'+i,'./data')\n",
        "\n",
        "try:\n",
        "  shutil.move('./signnames.csv','./data')\n",
        "except:\n",
        "  print('No CSV file was found')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cklYuIJOPOma"
      },
      "outputs": [],
      "source": [
        "#@title Loading Train/Test/Validation data\n",
        "training_file = './data/train.p'\n",
        "validation_file = './data/valid.p'\n",
        "testing_file = './data/test.p'\n",
        "\n",
        "with open (training_file, mode='rb') as f:\n",
        "  train = pickle.load(f)\n",
        "with open (validation_file, mode='rb') as f:\n",
        "  valid = pickle.load(f)\n",
        "with open (testing_file, mode='rb') as f:\n",
        "  test = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt3SF18vcYrj",
        "outputId": "5f8550b9-9876-4d65-8e0d-3cc59724f3c4"
      },
      "outputs": [],
      "source": [
        "#@title Read Sign names/classes\n",
        "signs_classes = []\n",
        "os.chdir('./data')\n",
        "with open ('signnames.csv', 'r') as file:\n",
        "  signnames = csv.reader(file, delimiter = ',')\n",
        "  next(signnames,None)\n",
        "  for row in signnames:\n",
        "    print(row)\n",
        "    signs_classes.append(row[1])\n",
        "  file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYc7sbPtgkIf",
        "outputId": "a953e585-8699-4522-b4ff-3002b53f2bbc"
      },
      "outputs": [],
      "source": [
        "#@title Data info\n",
        "X_train, Y_train = train['features'], train['labels']\n",
        "X_valid, Y_valid = valid['features'], valid['labels']\n",
        "X_test, Y_test = test['features'], test['labels']\n",
        "n_classes = len(np.unique(Y_train))\n",
        "\n",
        "print(\"Number of train samples: \", X_train.shape[0])\n",
        "print(\"Number of validation samples: \", X_valid.shape[0])\n",
        "print(\"Number of test samples: \", X_test.shape[0])\n",
        "print(\"Number of classses: \", n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaPg_PB9h5F6"
      },
      "outputs": [],
      "source": [
        "def show_images(data,y_data, label=\"\", cmap=None, n_images = 10):\n",
        "  plt.figure(figsize = (n_images*2,n_images*2))\n",
        "  for i in range(n_images):\n",
        "    plt.subplot(1,n_images,i+1)\n",
        "    ind = np.random.randint(0,len(data))\n",
        "    if len(data[ind].shape) == 2:\n",
        "      cmap = 'gray'\n",
        "    \n",
        "    plt.imshow(data[ind],cmap = cmap)\n",
        "    plt.xlabel(signs_classes[y_data[ind]], fontsize = 8)\n",
        "    plt.ylabel(label, fontsize = 8)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "d2XKySPSkOcg",
        "outputId": "d4f2681f-0b8a-4ff1-ffe6-c8e927ce44d2"
      },
      "outputs": [],
      "source": [
        "#@title Show samples of each group\n",
        "show_images(X_train,Y_train,'Traning examples')\n",
        "show_images(X_test,Y_test,'Testing examples')\n",
        "show_images(X_valid,Y_valid,'Validation examples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CB7AVvUNk5gq"
      },
      "outputs": [],
      "source": [
        "def show_hist(data, label):\n",
        "  plt.hist(data, bins = n_classes)\n",
        "  plt.xlabel(label)\n",
        "  plt.ylabel('class count')\n",
        "  plt.grid('off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        },
        "id": "h4NG5eZdkb6d",
        "outputId": "7603569d-dfe9-430c-f475-ec04ed87545d"
      },
      "outputs": [],
      "source": [
        "#@title Show groups histogram\n",
        "show_hist(Y_train, \"Training examples\")\n",
        "show_hist(Y_test, \"Testing examples\")\n",
        "show_hist(Y_valid, \"Validation examples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPsG5QLBmK1p"
      },
      "outputs": [],
      "source": [
        "X_train, Y_train = shuffle(X_train, Y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSHVAg1yn8Vy"
      },
      "outputs": [],
      "source": [
        "def convert_to_gray(image):\n",
        "  \n",
        "  return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "yzh-PaHYoUl2",
        "outputId": "65872b50-1093-4c18-c81d-2a44f827724f"
      },
      "outputs": [],
      "source": [
        "#@title Convert to gray scale images \n",
        "gray_images = list(map(convert_to_gray,X_train))\n",
        "show_images(gray_images,Y_train)\n",
        "np.shape(gray_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hR8bbhkLojxn"
      },
      "outputs": [],
      "source": [
        "def hist_equalization(image):\n",
        "  kernel = morp.disk(30)\n",
        "  return rank.equalize(image, selem=kernel)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KZ7eK5tNz_N"
      },
      "outputs": [],
      "source": [
        "def adapt_hist_equalization(image,clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2,2))):\n",
        "  return clahe.apply(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "pSVGrFYd39Te",
        "outputId": "00764c71-c6a6-4e22-cf68-a064bb4bf66c"
      },
      "outputs": [],
      "source": [
        "#@title Perform histogram equalization\n",
        "equalizied_gray_images = list(map(hist_equalization,gray_images))\n",
        "show_images(equalizied_gray_images,Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJhwhQUY4hGd"
      },
      "outputs": [],
      "source": [
        "def norm_image(data):\n",
        "  \n",
        "  normalized_images = np.array(data,dtype = np.float32)/255\n",
        "  return np.expand_dims(normalized_images, axis=-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRexAE6t6iJh"
      },
      "outputs": [],
      "source": [
        "def preprocess(x_data,y_data, n_classes = 43):\n",
        "  gray_images = list(map(convert_to_gray,x_data))\n",
        "  hist_equal_images = list(map(adapt_hist_equalization,gray_images))\n",
        "  norm_images = norm_image(hist_equal_images)\n",
        "  y_data = to_categorical(y_data, n_classes)\n",
        "  return norm_images, y_data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4OdfrPpoD6y"
      },
      "outputs": [],
      "source": [
        "def ConvBlock(model, pool, n_filters, mu, sigma):\n",
        "  model = Conv2D(n_filters, kernel_size = 2, padding = 'same',\n",
        "                 activation = 'relu', \n",
        "                 kernel_initializer = random_normal(mean = mu,stddev = sigma))(model)\n",
        "  \n",
        "  model = Conv2D(n_filters, kernel_size = 2, padding = 'same',\n",
        "                 activation = 'relu', \n",
        "                 kernel_initializer = random_normal(mean = mu,stddev = sigma))(model)\n",
        "  model = MaxPooling2D(pool_size = 2, strides = 2, padding = 'valid')(model)\n",
        "  model = Dropout(0.5)(model)\n",
        "  return model\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64ZkxfXZedu_"
      },
      "outputs": [],
      "source": [
        "def VGG_variation(input_shape,nf=32):\n",
        "  \n",
        "  inputs = x = Input(input_shape)\n",
        "  for i in range(3):\n",
        "    x = ConvBlock(x,pool = True, n_filters = nf * (i+2), mu = 0, sigma = 0.1)  \n",
        "  \n",
        "  x = Flatten()(x)\n",
        "  for _ in range(2):\n",
        "    x = Dense(units = 128, activation = 'relu')(x)\n",
        "  output = Dense(units = 43, activation = 'softmax')(x)\n",
        "  VGG_var_model = Model(inputs = inputs, outputs = output)\n",
        "  opti = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "  VGG_var_model.compile(optimizer = opti, loss = 'categorical_crossentropy',\n",
        "                       metrics = ['accuracy','categorical_crossentropy'])\n",
        "  VGG_var_model.summary()\n",
        "  return VGG_var_model\n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IulGx0eAlrF8"
      },
      "outputs": [],
      "source": [
        "class My_Callback(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        print(\"train begins!\")\n",
        "        return\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        print(\"-\", end='')\n",
        "        flag_val=True\n",
        "        if epoch%5==0:\n",
        "            train_acc = logs.get(\"acc\")\n",
        "            train_loss = logs.get(\"loss\")\n",
        "            try:\n",
        "                val_acc = logs.get(\"val_acc\")\n",
        "                val_loss = logs.get(\"val_loss\")\n",
        "            except:\n",
        "                flag_val=False\n",
        "            if flag_val:\n",
        "                print(\"\\n%d\"%epoch, \"\\ttrain_loss: \", train_loss,\n",
        "                      \"\\tval_loss: \", val_loss, \"\\ttrain_acc:\", train_acc, \n",
        "                      \"\\tval_acc:\", val_acc)\n",
        "            else:\n",
        "                print(\"\\n%d\"%epoch, \"\\ttrain_loss: \",\n",
        "                      train_loss, \"\\ttrain_acc:\", train_acc)    \n",
        "        return\n",
        "\n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=10,\n",
        "                              verbose=1, mode='auto', min_lr=1e-12)\n",
        "my_callback = My_Callback()\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"VGG_GermanSigns_classification.h5\", monitor='loss', \n",
        "                             verbose=0, save_best_only=True, save_weights_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBdWYBv635Y1"
      },
      "outputs": [],
      "source": [
        "#@title Preprocess the data\n",
        "X_train_processed, Y_train_cat = preprocess(X_train,Y_train)\n",
        "X_valid_processed, Y_valid_cat = preprocess(X_valid, Y_valid)\n",
        "#class_weights = create_class_weights(Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t02FWrAa9QkH",
        "outputId": "346bed29-4120-4212-e54f-7b166e08fe61"
      },
      "outputs": [],
      "source": [
        "#@title Create a variation of VGG model\n",
        "VGG_model = VGG_variation(X_train_processed.shape[1:])\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "weights = compute_class_weight('balanced',classes = np.unique(Y_train),y = Y_train)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rms1mlOtysSF",
        "outputId": "76ef9423-f3bc-489b-f429-b8879bd09510"
      },
      "outputs": [],
      "source": [
        "#@title Training\n",
        "model_history = VGG_model.fit(X_train_processed, Y_train_cat, batch_size=batch_size, epochs=epochs, \n",
        "                    validation_data=(X_valid_processed,Y_valid_cat),shuffle=True,\n",
        "                    callbacks = [my_callback, reduce_lr, checkpoint],verbose=0,)\n",
        "                    #class_weight = weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "id": "EXa4yYfU94HF",
        "outputId": "5f0bcff3-7b26-4c46-8db2-8a30340e95f3"
      },
      "outputs": [],
      "source": [
        "#@title Plotting ACC and LOSS of training\n",
        "# Accuracy\n",
        "plt.figure(figsize = (8,6))\n",
        "plt.plot(model_history.history['accuracy'],'r')\n",
        "plt.grid('off')\n",
        "plt.plot(model_history.history['val_accuracy'],'g')\n",
        "plt.xticks()\n",
        "plt.xlabel(\"Num of Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training Accuracy vs Validation Accuracy\")\n",
        "plt.legend(['train','validation'])\n",
        "plt.show()\n",
        "# Loss \n",
        "plt.figure(figsize = (8,6))\n",
        "plt.grid('off')\n",
        "plt.plot(model_history.history['loss'],'r')\n",
        "plt.plot(model_history.history['val_loss'],'g')\n",
        "plt.xticks()\n",
        "plt.xlabel(\"Num of Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss vs Validation Loss\")\n",
        "plt.legend(['train','validation'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IErQsGxFs3jU"
      },
      "outputs": [],
      "source": [
        "#@title Loading best result weights\n",
        "VGG_model.load_weights(\"VGG_GermanSigns_classification.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thxBfiKOGP1b"
      },
      "outputs": [],
      "source": [
        "#@title Preprocessing and predicting the test group\n",
        "X_test_processed, Y_test_cat = preprocess(X_test, Y_test)\n",
        "predicted = VGG_model.predict(X_test_processed)\n",
        "Y_pred = np.argmax(predicted, axis = 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1BdAHW7-HpPH",
        "outputId": "cb801ec1-8cc2-4a13-c7f7-808bc2ae2513"
      },
      "outputs": [],
      "source": [
        "#@title Calculating and presenting the confusion matrix\n",
        "cm = confusion_matrix(np.argmax(Y_test_cat,axis=1),Y_pred)\n",
        "plt.figure(figsize = (25,25))\n",
        "sn.set(font_scale=1)\n",
        "sn.heatmap(cm, cmap = 'viridis', annot = True, annot_kws = {'size': 8})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtUuaz85emmT",
        "outputId": "e59ab635-cad3-4886-84bc-2bef69a05d4b"
      },
      "outputs": [],
      "source": [
        "#@title Printing the results\n",
        "total_accurate = 0\n",
        "for i in range (cm.shape[0]):\n",
        "  print('The accuracy of class No.{} is: {:.2f}%' .format(i+1,100*cm[i,i]/cm[i].sum()))\n",
        "  total_accurate += cm[i,i]\n",
        "  \n",
        "print('The total accuracy is: {:.2f}%' .format(100*total_accurate/cm.sum()))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Traffic_sign_recognition_VGG.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
